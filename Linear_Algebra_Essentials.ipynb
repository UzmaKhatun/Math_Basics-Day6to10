{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bd18512-3c44-4970-9e16-b775d38c9925",
   "metadata": {},
   "source": [
    "# Day-10 Of \n",
    "# <b>#100 Days of Machine Learning</b>\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f257bc-5bb2-4230-8f69-6680841abdd9",
   "metadata": {},
   "source": [
    "# Linear Algebra Essentials\n",
    "## Vectors, Matrices, Dot Product, Matrix Multiplication"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a6cdd3-8bcf-4acd-b8c9-bbd343b6b1d6",
   "metadata": {},
   "source": [
    "# I. Vectors\n",
    "## Definition\n",
    "### A vector is a mathematical object that has both magnitude (length) and direction. It can be represented geometrically as a directed line segment. In machine learning, vectors are often used to represent data points or features.\n",
    "\n",
    "## Representation:\n",
    "### Column vector : $[\\mathbf{v} = \\begin{bmatrix} v_1 \\ v_2 \\ \\vdots \\ v_n \\end{bmatrix}]$\n",
    "\n",
    "### Row vector : $[\\mathbf{v}^T = \\begin{bmatrix} v_1 & v_2 & \\cdots & v_n \\end{bmatrix}]$\n",
    "#### Where $( v_1, v_2, ..., v_n )$ are the components or elements of the vector.\n",
    "\n",
    "## Dimensionality: The number of components in a vector is called its dimension. For example, a vector with 3 components is a 3-dimensional vector.\n",
    "### Examples\n",
    "### 2D Vector: $( \\mathbf{v} = \\begin{bmatrix} 2 \\ 3 \\end{bmatrix} )$ represents a vector in the xy-plane, starting at the origin and ending at the point $(2, 3)$.\n",
    "### 3D Vector: $( \\mathbf{v} = \\begin{bmatrix} 1 \\ 0 \\ -1 \\end{bmatrix} )$ represents a vector in 3D space.\n",
    "### Feature Vector: In machine learning, a data point with multiple features (e.g., height, weight, age) can be represented as a feature vector. For instance, a person's data might be represented as $( \\mathbf{x} = \\begin{bmatrix} 170 \\text{ cm} \\ 70 \\text{ kg} \\ 30 \\text{ years} \\end{bmatrix} )$\n",
    "\n",
    "## Vector Operations\n",
    "### Addition: Add corresponding components of two vectors of the same dimension.\n",
    "### $[\\begin{bmatrix} a_1 \\ a_2 \\end{bmatrix} + \\begin{bmatrix} b_1 \\ b_2 \\end{bmatrix} = \\begin{bmatrix} a_1 + b_1 \\ a_2 + b_2 \\end{bmatrix}]$\n",
    "\n",
    "### Scalar Multiplication: Multiply each component of a vector by a scalar (a number).\n",
    "### $[c \\begin{bmatrix} a_1 \\ a_2 \\end{bmatrix} = \\begin{bmatrix} ca_1 \\ ca_2 \\end{bmatrix}]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0bce9ef-88c2-4e73-b03b-01af2fa71f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6 8]\n",
      "[4 6]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "v1 = np.array([2, 3])\n",
    "v2 = np.array([4, 5])\n",
    "\n",
    "print(v1 + v2)  # Vector addition\n",
    "print(2 * v1)   # Scalar multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4705e9e4-fcac-46fb-a68e-c2e3bcdfef0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 6]\n",
      "[-2 -2]\n",
      "[3 6]\n"
     ]
    }
   ],
   "source": [
    "v1 = np.array([1, 2])\n",
    "v2 = np.array([3, 4])\n",
    "\n",
    "print(v1 + v2)  # [4, 6]\n",
    "print(v1 - v2)  # [-2, -2]\n",
    "print(3 * v1)   # [3, 6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482f116a-dadf-4e22-bb5a-c7aebe7e302a",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5a855b-e0c3-49b9-9705-a1b200339bfb",
   "metadata": {},
   "source": [
    "# II. Matrices\n",
    "## Definition\n",
    "### A matrix is a rectangular array of numbers, symbols, or expressions, arranged in rows and columns.\n",
    "### Representation : $[\\mathbf{A} = \\begin{bmatrix} a_{11} & a_{12} & \\cdots & a_{1n} \\a_{21} & a_{22} & \\cdots & a_{2n} \\\\vdots & \\vdots & \\ddots & \\vdots \\a_{m1} & a_{m2} & \\cdots & a_{mn} \\end{bmatrix}]$\n",
    "#### Where $( a_{ij} )$ represents the element in the ( i )-th row and ( j )-th column.\n",
    "\n",
    "### Dimensions: A matrix with ( m ) rows and ( n ) columns is said to be an $( m \\times n )$ matrix.\n",
    "### Examples\n",
    "### 2x2 Matrix : $( \\mathbf{A} = \\begin{bmatrix} 1 & 2 \\ 3 & 4 \\end{bmatrix} )$\n",
    "### 3x1 Matrix (Column Vector) : $( \\mathbf{b} = \\begin{bmatrix} 5 \\ 6 \\ 7 \\end{bmatrix} )$\n",
    "### $1x3$ Matrix (Row Vector) : $( \\mathbf{c} = \\begin{bmatrix} 8 & 9 & 10 \\end{bmatrix} )$\n",
    "## Matrix Operations\n",
    "### Addition: Add corresponding elements of two matrices of the same dimensions.\n",
    "### $[\\begin{bmatrix} a_{11} & a_{12} \\ a_{21} & a_{22} \\end{bmatrix} + \\begin{bmatrix} b_{11} & b_{12} \\ b_{21} & b_{22} \\end{bmatrix} = \\begin{bmatrix} a_{11} + b_{11} & a_{12} + b_{12} \\ a_{21} + b_{21} & a_{22} + b_{22} \\end{bmatrix}]$\n",
    "\n",
    "### Scalar Multiplication: Multiply each element of a matrix by a scalar.\n",
    "### $[c \\begin{bmatrix} a_{11} & a_{12} \\ a_{21} & a_{22} \\end{bmatrix} = \\begin{bmatrix} ca_{11} & ca_{12} \\ ca_{21} & ca_{22} \\end{bmatrix}]$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a227dd2-3682-4067-bf2d-b269609fe69f",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21089d7-07d8-46b5-983f-8fbb54823ce5",
   "metadata": {},
   "source": [
    "# III. Matrix Multiplication\n",
    "## Definition\n",
    "### Matrix multiplication is an operation that produces a new matrix from two matrices.  For the product of two matrices to be defined, the number of columns in the first matrix must equal the number of rows in the second matrix.\n",
    "### Rule: If $( \\mathbf{A} )$ is an $( m \\times n )$ matrix and $( \\mathbf{B} )$ is an $( n \\times p )$ matrix, then their product $( \\mathbf{C} = \\mathbf{A} \\mathbf{B} )$ is an $( m \\times p )$ matrix. The element $( c_{ij} ) of ( \\mathbf{C} )$ is calculated as the dot product of the ( i )-th row of $( \\mathbf{A} )$ and the ( j )-th column of $( \\mathbf{B} )$:\n",
    "### $[c_{ij} = a_{i1}b_{1j} + a_{i2}b_{2j} + \\cdots + a_{in}b_{nj} = \\sum_{k=1}^{n} a_{ik}b_{kj}]$\n",
    "## Example\n",
    "### Given matrices\n",
    "### $[\\mathbf{A} = \\begin{bmatrix} 1 & 2 \\ 3 & 4 \\end{bmatrix}, \\quad \\mathbf{B} = \\begin{bmatrix} 5 & 6 \\ 7 & 8 \\end{bmatrix}]$\n",
    "### The product $( \\mathbf{C} = \\mathbf{A} \\mathbf{B} )$ is:\n",
    "### $[\\mathbf{C} = \\begin{bmatrix} (1 \\times 5 + 2 \\times 7) & (1 \\times 6 + 2 \\times 8) \\ (3 \\times 5 + 4 \\times 7) & (3 \\times 6 + 4 \\times 8) \\end{bmatrix} = \\begin{bmatrix} 19 & 22 \\ 43 & 50 \\end{bmatrix}]$\n",
    "\n",
    "## Properties of Matrix Multiplication\n",
    "### - Not Commutative: In general, $( \\mathbf{A} \\mathbf{B} \\neq \\mathbf{B} \\mathbf{A} )$.\n",
    "### Associative: $( (\\mathbf{A} \\mathbf{B}) \\mathbf{C} = \\mathbf{A} (\\mathbf{B} \\mathbf{C}) )$.\n",
    "### Distributive: $( \\mathbf{A} (\\mathbf{B} + \\mathbf{C}) = \\mathbf{A} \\mathbf{B} + \\mathbf{A} \\mathbf{C} ) and ( (\\mathbf{A} + \\mathbf{B}) \\mathbf{C} = \\mathbf{A} \\mathbf{C} + \\mathbf{B} \\mathbf{C} ).$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376329ea-b53f-43d9-ac08-78617596d7f2",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dbfedac-1598-46b9-87ba-d2a1057052a2",
   "metadata": {},
   "source": [
    "# IV. Dot Product (Scalar Product)\n",
    "## Definition\n",
    "### The dot product is an operation that takes two vectors of the same dimension and returns a single number (a scalar).\n",
    "\n",
    "### Formula: For two vectors\n",
    "### $[\\mathbf{a} = \\begin{bmatrix} a_1 \\ a_2 \\ \\vdots \\ a_n \\end{bmatrix}, \\quad \\mathbf{b} = \\begin{bmatrix} b_1 \\ b_2 \\ \\vdots \\ b_n \\end{bmatrix}]$\n",
    "### The dot product is:\n",
    "### $[\\mathbf{a} \\cdot \\mathbf{b} = a_1b_1 + a_2b_2 + \\cdots + a_nb_n = \\sum_{i=1}^{n} a_i b_i]$\n",
    "### Example\n",
    "### Given vectors $( \\mathbf{a} = \\begin{bmatrix} 1 \\ 2 \\ 3 \\end{bmatrix} ) and ( \\mathbf{b} = \\begin{bmatrix} 4 \\ 5 \\ 6 \\end{bmatrix} )$, their dot product is:\n",
    "### $[\\mathbf{a} \\cdot \\mathbf{b} = (1 \\times 4) + (2 \\times 5) + (3 \\times 6) = 4 + 10 + 18 = 32]$\n",
    "### Geometric Interpretation\n",
    "#### The dot product is related to the angle $( \\theta )$ between the two vectors:\n",
    "### $[\\mathbf{a} \\cdot \\mathbf{b} = ||\\mathbf{a}|| \\ ||\\mathbf{b}|| \\cos(\\theta)]$\n",
    "### Where $( ||\\mathbf{a}|| ) and ( ||\\mathbf{b}|| )$ are the magnitudes $(lengths)$ of the vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6e69e5b-7db8-4fdd-89d8-17909afd610e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\n"
     ]
    }
   ],
   "source": [
    "v1 = np.array([5, 6, 7])\n",
    "v2 = np.array([1, 2, 3])\n",
    "\n",
    "print(np.dot(v1, v2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "525e5f6d-f3b2-4b41-bcbe-8c2dd4be8629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4  6]\n",
      " [10 12]]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[1, 2], [3, 4]])\n",
    "B = np.array([[2, 0], [1, 3]])\n",
    "\n",
    "result = np.dot(A, B)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4094a9-0e57-43af-ae54-cb971aad8540",
   "metadata": {},
   "source": [
    "## Why These Concepts Matter in Machine Learning\n",
    "### - Data Representation: Vectors and matrices are fundamental for representing data, from simple datasets to complex image and text data.\n",
    "### - Linear Models: Linear regression, logistic regression, and support vector machines rely heavily on vector and matrix operations.\n",
    "### - Neural Networks: Matrix multiplication is a core operation in neural networks for transforming and combining data.\n",
    "### - Dimensionality Reduction: Techniques like Principal Component Analysis (PCA) use linear algebra to reduce the dimensionality of data.\n",
    "### - Optimization: Many optimization algorithms used in machine learning, such as gradient descent, involve vector and matrix calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9837942-5928-4e7a-82dd-d478ec23e434",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
